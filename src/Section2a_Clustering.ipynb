{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = \"../data/EVChargingStationUsage.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_on_gpu(model, X_train, y_train, epochs=10):\n",
    "    # Convert to PyTorch tensors and move to GPU\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "    # Set up the optimizer and loss function\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4054/699914593.py:9: DtypeWarning: Columns (29,30,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(path_dataset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape = (259415, 33)\n",
      "Missing data in column 'Station Name': 0\n",
      "Missing data in column 'MAC Address': 0\n",
      "Missing data in column 'Org Name': 0\n",
      "Missing data in column 'Start Date': 0\n",
      "Missing data in column 'Start Time Zone': 0\n",
      "Missing data in column 'End Date': 0\n",
      "Missing data in column 'End Time Zone': 0\n",
      "Missing data in column 'Transaction Date (Pacific Time)': 209\n",
      "Missing data in column 'Total Duration (hh:mm:ss)': 0\n",
      "Missing data in column 'Charging Time (hh:mm:ss)': 0\n",
      "Missing data in column 'Energy (kWh)': 0\n",
      "Missing data in column 'GHG Savings (kg)': 0\n",
      "Missing data in column 'Gasoline Savings (gallons)': 0\n",
      "Missing data in column 'Port Type': 9\n",
      "Missing data in column 'Port Number': 0\n",
      "Missing data in column 'Plug Type': 0\n",
      "Missing data in column 'EVSE ID': 78948\n",
      "Missing data in column 'Address 1': 0\n",
      "Missing data in column 'City': 0\n",
      "Missing data in column 'State/Province': 0\n",
      "Missing data in column 'Postal Code': 0\n",
      "Missing data in column 'Country': 0\n",
      "Missing data in column 'Latitude': 0\n",
      "Missing data in column 'Longitude': 0\n",
      "Missing data in column 'Currency': 1788\n",
      "Missing data in column 'Fee': 0\n",
      "Missing data in column 'Ended By': 248\n",
      "Missing data in column 'Plug In Event Id': 0\n",
      "Missing data in column 'Driver Postal Code': 8402\n",
      "Missing data in column 'User ID': 7677\n",
      "Missing data in column 'County': 84665\n",
      "Missing data in column 'System S/N': 78948\n",
      "Missing data in column 'Model Number': 78948\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the CSV file\n",
    "def load_csv(path_dataset):\n",
    "    # Load data into a DataFrame\n",
    "    data = pd.read_csv(path_dataset)\n",
    "    return data\n",
    "\n",
    "path_dataset = \"../data/EVChargingStationUsage.csv\"\n",
    "data = load_csv(path_dataset)\n",
    "\n",
    "# Display the first few rows, shape, and column names\n",
    "# print(data.head())\n",
    "print(f\"Shape = {data.shape}\")\n",
    "# print(f\"Attribute Labels = \\n {data.columns}\")\n",
    "\n",
    "# Loop over each column to check for missing values\n",
    "for col in data.columns:  # Iterate over the column names directly\n",
    "    missing_data = data[col].isnull().sum()  # Count the missing values in the column\n",
    "    print(f\"Missing data in column '{col}': {missing_data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values, missing values, and counts have been written to 'unique_values_output.txt'\n"
     ]
    }
   ],
   "source": [
    "# Open a file to write the output\n",
    "with open(\"unique_values_output.txt\", \"w\") as f:\n",
    "    # Loop through all columns in the dataset and write missing values, unique values, and counts to the file\n",
    "    for column in data.columns:\n",
    "        # Count unique values\n",
    "        unique_values = data[column].unique()\n",
    "        num_unique = len(unique_values)\n",
    "        \n",
    "        # Count missing values\n",
    "        missing_values = data[column].isnull().sum()\n",
    "        \n",
    "        # Write formatted output\n",
    "        f.write(f\"\\n{'*' * 50}\\n\")  # Special formatting for column names\n",
    "        f.write(f\"Column: {column.upper()}  {'*' * (50 - len(column) - 9)}\\n\")  # Make column name more visible\n",
    "        f.write(f\"{'-' * 50}\\n\")\n",
    "        \n",
    "        # Print missing values first\n",
    "        f.write(f\"Missing values: {missing_values}\\n\")\n",
    "        \n",
    "        # Write unique values with a limit of 100\n",
    "        f.write(f\"Unique values (Count: {num_unique}):\\n\")\n",
    "        if num_unique > 100:\n",
    "            # Limit to the first 100 unique values and print a message for the rest\n",
    "            f.write(\"\\n\".join(map(str, unique_values[:100])) + \"\\n\")\n",
    "            f.write(f\"... and {num_unique - 100} more unique values (omitted for brevity).\\n\")\n",
    "        else:\n",
    "            f.write(\"\\n\".join(map(str, unique_values)) + \"\\n\")\n",
    "        \n",
    "        f.write(f\"{'-' * 50}\\n\")  # Separator between columns for better readability\n",
    "\n",
    "print(\"Unique values, missing values, and counts have been written to 'unique_values_output.txt'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
